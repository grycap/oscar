{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>OSCAR is a framework to efficiently support on-premises FaaS (Functions as a Service)for general-purpose file-processing computing applications. It represents the porting to an on-premises scenario of the SCAR framework, which supports a High Throughput Computing Programming Model to create highly-parallel event-driven file-processing serverless applications that execute on customized runtime environments provided by Docker containers run on AWS Lambda.</p>"},{"location":"#goal","title":"Goal","text":"<p>Users upload files to a bucket and this automatically triggers the execution of parallel invocations to a function responsible for processing each file. Output files are delivered into an output bucket for the convenience of the user. Highly scalable HTTP-based endpoints can also be offered to expose a generic application. A user-provided shell script is executed inside the container run from the user-defined Docker image to achieve the right execution environment for the application.</p>"},{"location":"#components","title":"Components","text":"<p>OSCAR runs on an elastic Kubernetes cluster that is deployed using:</p> <ul> <li>EC3, an open-source tool to deploy compute     clusters that can horizontally scale in terms of the number of nodes with multiple     plugins.</li> <li>IM, an open-source virtual infrastructure     provisioning tool for multi-Clouds.</li> <li>CLUES, an elasticity manager that     horizontally scales in and out the number of nodes of the Kubernetes     cluster according to the workload.</li> </ul> <p>The following components are deployed inside the Kubernetes cluster in order to support the OSCAR platform: - MinIO, a high-performance distributed object storage     server that provides an API compatible with S3. - Knative, a Serverless framework to serve     container-based applications for synchronous invocations (default     Serverless Backend). - OpenFaaS, a FaaS platform that allows creating     functions executed via HTTP requests. - OSCAR, the main application, responsible for the management of the services     and the integration of the different components to support event-driven     serverless computing for file processing. It includes a web-based GUI aimed     at end users to facilitate interaction with OSCAR.</p> <p>As external storage providers, the following services can be used:</p> <ul> <li>External MinIO servers, which may be in clusters other     than the platform.</li> <li>[Amazon S3, AWS's object storage     service that offers industry-leading scalability, data availability,     security, and performance in the public Cloud.</li> <li>Onedata, the global data access solution for science     used in the EGI Federated Cloud.</li> <li>Any storage provider that can be accessible through     WebDAV protocol. An example of a storage provider     supporting this protocol is dCache, a storage     middleware system capable of managing the storage and exchange of large data     quantities.</li> </ul> <p>Note: All of the mentioned storage providers can be used as output, but only MinIO can be used as input.</p> <p>An OSCAR cluster can be accessed via its REST API, the [web-based UI and the command-line interface provided by oscar-cli.</p>"},{"location":"about/","title":"About","text":"<p>OSCAR has been developed by the Grid and High Performance Computing Group (GRyCAP) at the Instituto de Instrumentaci\u00f3n para Imagen Molecular (I3M) from the Universitat Polit\u00e8cnica de Val\u00e8ncia (UPV).</p> <p> </p> <p>This development is partially funded by the EGI Strategic and Innovation Fund and it can be deployed in the EGI Platform through the EGI Applications on Demand portal.</p>"},{"location":"about/#contact","title":"Contact","text":"<p>If you have any trouble please open an issue or email us.</p>"},{"location":"api/","title":"OpenAPI Specification","text":"<p>OSCAR exposes a secure REST API available at the Kubernetes master's node IP through an ingress. This API has been described following the OpenAPI Specification and it can be consulted bellow.</p> <p></p>      SwaggerUIBundle({       url: 'api.yaml',       dom_id: '#swagger-ui',     })"},{"location":"deploy-ansible/","title":"Ansible playbook to deploy K3s and the OSCAR platform","text":"<p>The folder <code>deploy/ansible</code> contains all the necessary files to deploy a K3s cluster together with the OSCAR platform using Ansible. This way, a minified Kubernetes distribution can be used to configure OSCAR on IoT devices located at the Edge, such as Raspberry PIs. Note that this playbook can also be applied to quickly spread the OSCAR platform on top of any machine or already started cloud instance since the playbook is compatible with GNU/Linux on ARM64 and AMD64 architectures.</p>"},{"location":"deploy-ansible/#requirements","title":"Requirements","text":"<p>In order to use the playbook, you must install the following components:</p> <ul> <li>Ansible, following this guide.</li> <li>The <code>netaddr</code>   python library.</li> <li>OpenSSH, to remotely access the hosts to be configured.</li> </ul>"},{"location":"deploy-ansible/#usage","title":"Usage","text":""},{"location":"deploy-ansible/#clone-the-folder","title":"Clone the folder","text":"<p>First of all, you must clone the OSCAR repo:</p> <pre><code>git clone https://github.com/grycap/oscar.git\n</code></pre> <p>And place into the <code>ansible</code> directory:</p> <pre><code>cd oscar/deploy/ansible\n</code></pre>"},{"location":"deploy-ansible/#ssh-configuration","title":"SSH configuration","text":"<p>As Ansible is an agentless automation tool, you must configure the <code>~/.ssh/config</code> file for granting access to the hosts to be configured via the SSH protocol. This playbook will use the <code>Host</code> field from SSH configuration to set the hostnames of the nodes, so please take care of naming them properly.</p> <p>Below you can find an example of a configuration file for four nodes, being the <code>front</code> the only one with a public IP, so it will be used as a proxy for the SSH connection to the working nodes (<code>ProxyJump</code> option) via its internal network.</p> <pre><code>Host front\n  HostName &lt;PUBLIC_IP&gt;\n  User ubuntu\n  IdentityFile ~/.ssh/my_private_key\n\nHost wn1\n  HostName &lt;PRIVATE_IP&gt;\n  User ubuntu\n  IdentityFile ~/.ssh/my_private_key\n  ProxyJump front\n\nHost wn2\n  HostName &lt;PRIVATE_IP&gt;\n  User ubuntu\n  IdentityFile ~/.ssh/my_private_key\n  ProxyJump front\n\nHost wn3\n  HostName &lt;PRIVATE_IP&gt;\n  User ubuntu\n  IdentityFile ~/.ssh/my_private_key\n  ProxyJump front\n</code></pre>"},{"location":"deploy-ansible/#configuration-of-the-inventory-file","title":"Configuration of the inventory file","text":"<p>Now, you have to edit the <code>hosts</code> file and add the hosts to be configured. Note that only one node must be set in the <code>[front]</code> section, while one or more nodes can be configured as working nodes of the cluster in the <code>[wn]</code> section. For example, for the previous SSH configuration the <code>hosts</code> inventory file should look like this:</p> <pre><code>[front]\n; Put here the frontend node as defined in .ssh/config (Host)\nfront\n\n[wn]\n; Put here the working nodes (one per line) as defined in the .ssh/config (Host)\nwn1\nwn2\nwn3\n</code></pre>"},{"location":"deploy-ansible/#setting-up-the-playbook-variables","title":"Setting up the playbook variables","text":"<p>You also need to set up some parameters for the configuration of the cluster and OSCAR components, like OSCAR and MinIO credentials and DNS endpoints to configure the Kubernetes Ingress and cert-manager to securely expose the services. To do it, please edit the <code>vars.yaml</code> file and update the variables:</p> <pre><code>---\n# K3s version to be installed\nkube_version: v1.22.3+k3s1\n# Token to login in K3s and the Kubernetes Dashboard\nkube_admin_token: kube-token123\n# Password for OSCAR\noscar_password: oscar123\n# DNS name for the OSCAR Ingress and Kubernetes Dashboard (path \"/dashboard/\")\ndns_host: oscar-cluster.example.com\n# Password for MinIO\nminio_password: minio123\n# DNS name for the MinIO API Ingress\nminio_dns_host: minio.oscar-cluster.example.com\n# DNS name for the MinIO Console Ingress\nminio_dns_host_console: minio-console.oscar-cluster.example.com\n</code></pre>"},{"location":"deploy-ansible/#installation-of-the-required-ansible-roles","title":"Installation of the required ansible roles","text":"<p>To install the required roles you only have to run:</p> <pre><code>ansible-galaxy install -r install_roles.yaml --force\n</code></pre> <p>The <code>--force</code> argument ensures you have the latest version of the roles.</p>"},{"location":"deploy-ansible/#running-the-playbook","title":"Running the playbook","text":"<p>Finally, with the following command the ansible playbook will be executed, configuring the nodes set in the <code>hosts</code> inventory file:</p> <pre><code>ansible-playbook -i hosts oscar-k3s.yaml\n</code></pre>"},{"location":"deploy-ec3/","title":"Deployment with EC3","text":"<p>In order to deploy an elastic Kubernetes cluster with the OSCAR platform, it is preferable to use the IM Dashboard. Alternatively, you can also use EC3, a tool that deploys elastic virtual clusters. EC3 uses the Infrastructure Manager (IM) to deploy such clusters on multiple Cloud back-ends. The installation details can be found here, though this section includes the relevant information to get you started.</p>"},{"location":"deploy-ec3/#prepare-ec3","title":"Prepare EC3","text":"<p>Clone the EC3 repository:</p> <pre><code>git clone https://github.com/grycap/ec3\n</code></pre> <p>Download the OSCAR template into the <code>ec3/templates</code> folder:</p> <pre><code>cd ec3\nwget -P templates https://raw.githubusercontent.com/grycap/oscar/master/templates/oscar.radl\n</code></pre> <p>Create an <code>auth.txt</code> authorization file with valid credentials to access your Cloud provider. As an example, to deploy on an OpenNebula-based Cloud site the contents of the file would be:</p> <pre><code>type = OpenNebula; host = opennebula-host:2633;\nusername = your-user;\npassword = you-password\n</code></pre> <p>Modify the corresponding RADL template in order to determine the appropriate configuration for your deployment:</p> <ul> <li>Virtual Machine Image identifiers</li> <li>Hardware Configuration</li> </ul> <p>As an example, to deploy in OpenNebula, one would modify the <code>ubuntu-opennebula.radl</code> (or create a new one).</p>"},{"location":"deploy-ec3/#deploy-the-cluster","title":"Deploy the cluster","text":"<p>To deploy the cluster, execute:</p> <pre><code>./ec3 launch oscar-cluster oscar ubuntu-opennebula -a auth.txt\n</code></pre> <p>This will take several minutes until the Kubernetes cluster and all the required services have been deployed. You will obtain the IP of the front-end of the cluster and a confirmation message that the front-end is ready. Notice that it will still take few minutes before the services in the Kubernetes cluster are up &amp; running.</p>"},{"location":"deploy-ec3/#check-the-cluster-state","title":"Check the cluster state","text":"<p>The cluster will be fully configured when all the Kubernetes pods are in the <code>Running</code> state.</p> <pre><code> ./ec3 ssh oscar-cluster\n sudo kubectl get pods --all-namespaces\n</code></pre> <p>Notice that initially only the front-end node of the cluster is deployed. As soon as the OSCAR framework is deployed, together with its services, the CLUES elasticity manager powers on a new (working) node on which these services will be run.</p> <p>You can see the status of the provisioned node(s) by issuing:</p> <pre><code> clues status\n</code></pre> <p>which obtains:</p> <pre><code>| node            |state| enabled |time stable|(cpu,mem) used |(cpu,mem) total|\n|-----------------|-----|---------|-----------|---------------|---------------|\n| wn1.localdomain | used| enabled | 00h00'49\" | 0.0,825229312 | 1,1992404992  |\n| wn2.localdomain | off | enabled | 00h06'43\" | 0,0           | 1,1073741824  |\n| wn3.localdomain | off | enabled | 00h06'43\" | 0,0           | 1,1073741824  |\n| wn4.localdomain | off | enabled | 00h06'43\" | 0,0           | 1,1073741824  |\n| wn5.localdomain | off | enabled | 00h06'43\" | 0,0           | 1,1073741824  |\n</code></pre> <p>The working nodes transition from <code>off</code> to <code>powon</code> and, finally, to the <code>used</code> status.</p>"},{"location":"deploy-ec3/#default-service-endpoints","title":"Default Service Endpoints","text":"<p>Once the OSCAR framework is running on the Kubernetes cluster, the endpoints described in the following table should be available. Most of the passwords/tokens are dynamically generated at deployment time and made available in the <code>/var/tmp</code> folder of the front-end node of the cluster.</p> Service Endpoint Default User Password File OSCAR https://{FRONT_NODE} oscar oscar_password MinIO https://{FRONT_NODE}:30300 minio minio_secret_key OpenFaaS http://{FRONT_NODE}:31112 admin gw_password Kubernetes API https://{FRONT_NODE}:6443 tokenpass Kube. Dashboard https://{FRONT_NODE}:30443 dashboard_token <p>Note that <code>{FRONT_NODE}</code> refers to the public IP of the front-end of the Kubernetes cluster.</p> <p>For example, to get the OSCAR password, you can execute:</p> <pre><code>./ec3 ssh oscar-cluster cat /var/tmp/oscar_password\n</code></pre>"},{"location":"deploy-helm/","title":"Deployment on an existing Kubernetes cluster using Helm","text":"<p>OSCAR can also be deployed on any existing Kubernetes cluster through its helm chart. However, to make the platform work properly, the following dependencies must be satisfied.</p> <ul> <li>A StorageClass with the <code>ReadWriteMany</code> access mode must be configured in     the cluster for the creation of the persistent volume mounted on the service     containers. For this purpose, we use the     Kubernetes NFS-Client Provisioner,     but there are other     volume plugins     that support this access mode.</li> <li>MinIO must be deployed and properly configured in the cluster. Its     helm chart can be used     for this purpose. It is important to configure it properly to have access from     inside and outside the cluster, as the OSCAR's web interface connects directly     to its API. In the OSCAR helm chart, you must indicate the     values     corresponding to its credentials and endpoint.</li> </ul>"},{"location":"deploy-im-dashboard/","title":"Deployment with the IM Dashboard","text":"<p>An OSCAR cluster can be easily deployed on multiple Cloud back-ends without requiring any installation by using the Infrastructure Manager's Dashboard (IM Dashboard). This is a managed service provided by the GRyCAP research group at the Universitat Polit\u00e8cnica de Val\u00e8ncia to deploy customized virtual infrastructures across many Cloud providers.</p> <p>Using the IM Dashboard is the easiest and most convenient approach to deploy an OSCAR cluster. It also automatically allocates a DNS entry and TLS certificates to support HTTPS-based access to the OSCAR cluster and companion services (e.g. MinIO).</p> <p>This example shows how to deploy an OSCAR cluster on Amazon Web Services (AWS) with two nodes. Thanks to the IM, the very same procedure applies to deploy the OSCAR cluster in an on-premises Cloud (such as OpenStack) or any other Cloud provider supported by the IM.</p> <p>These are the steps:</p> <ol> <li> <p>Access the IM Dashboard</p> <p></p> <p>You will need to authenticate via EGI Check-In, which supports mutiple Identity Providers (IdP).</p> </li> <li> <p>Configure the Cloud Credentials</p> <p>Once logged in, you need to define the access credentials to the Cloud on which the OSCAR cluster will be deployed. These should be temporary credentials under the principle of least privilege (PoLP).</p> <p></p> <p></p> <p></p> <p>In our case we indicate an identifier for the set of credentials, the Access Key ID and the Secret Access Key for an IAM user that has privileges to deploy Virtual Machines in Amazon EC2.</p> </li> <li> <p>Select the OSCAR template</p> <p></p> </li> <li> <p>Customize and deploy the OSCAR cluster</p> <p>In this panel you can specify the number of Working Nodes (WNs) of the cluster together with the computational requirements for each node. We leave the default values. - Number of WNs in the oscar cluster: Number of working nodes. - Number of CPUs for the front-end node: Number of CPUs in the primary node. - Amount of Memory for the front-end node: RAM in the primary node. - Flavor name of the front-end node. Only required in case of special flavors i.e. with GPUs: Type of instance that will be selected in the front node. - Number of CPUs for the WNs: number of CPUs per working node. - Amount of Memory for the WNs: RAM per working node. - Flavor name of the WNs. Only required in case of special flavors i.e. with GPUs: Type of instance that will be selected in the working nodes. - Size of the extra HD added to the instance: Extra memory in the primary node. </p> <p>In this panel, specify the passwords to be employed to access the Kubernetes Web UI (Dashboard), to access the OSCAR web UI and to access the MinIO dashboard. These tokens can also be used for programmatic access to the respective services.</p> <ul> <li>Access Token for the Kubernetes admin user: It is the token to connect to the Dashboard of Kubernetes.</li> <li>OSCAR password: password to OSCAR.</li> <li>MinIO password 8 characters min.: password to MinIO.</li> <li>Email to be used in the Lets Encrypt issuer: It is an Email linked with the certificates in case the user has any questions.</li> <li>ID of the user that creates the infrastructure: unique identifier. Do not touch.</li> <li>VO to support: It supports OIDC log in. If there is nothing, only can connect the user who deploys, in case there is a VO, it can be the user who deploys and all people in the VO.</li> <li>Flag to add NVIDIA support: if you want to use NVIDIA.</li> <li>Flag to install Apache YuniKorn: if you are going to use YuniKorn. </li> </ul> <p>Now, choose the Cloud provider. The ID specified when creating the Cloud credentials will be shown. You will also need to specify the Amazon Machine Image (AMI) identifier. We chose an AMI based on Ubuntu 20.04 provided by Canonical whose identifier for the us-east-1 region is: ami-09e67e426f25ce0d7</p> <p>NOTE: You should obtain the AMI identifier for the latest version of the OS. This way, security patches will be already installed. You can obtain this AMI identifier from the AWS Marketplace or the Amazon EC2 service.</p> <p></p> <p>Give the infrastructure a name and press \"Submit\".</p> </li> <li> <p>Check the status of the deployment OSCAR cluster</p> <p>You will see that the OSCAR cluster is being deployed and the infrastructure reaches the status \"running\". The process will not finish until it reaches the state \"configured\".</p> <p></p> <p>If you are interested in understanding what is happening under the hood you can see the logs:</p> <p></p> </li> <li> <p>Accessing the OSCAR cluster</p> <p>Once reached the \"configured\" state, see the \"Outputs\" to obtain the different endpoints:</p> <ul> <li>console_minio_endpoint: This endpoint brings access to the MinIO web     user interface.</li> <li>dashboard_endpoint: This endpoint redirects to the Kubernetes dashboard     where the OSCAR cluster is deployed.</li> <li>local_oscarui_endpoint: This endpoint is where the OSCAR backend is     listening. It supports authentication only via basic-auth.</li> <li>minio_endpoint: Endpoint where the MinIO API is listening. If you     access it through a web browser, you will be redirected to     \"console_minio_endpoint\".</li> <li>oscarui_endpoint: Public endpoint of the OSCAR web user interface. It     supports OIDC connections via EGI Check-in, as well as basic auth.</li> </ul> <p></p> <p>The OSCAR UI can be accessed with the username <code>oscar</code> and the password you specified at deployment time.</p> <p></p> <p>The MinIO UI can be accessed with the username <code>minio</code> and the password you specified at deployment time.</p> <p></p> <p>The Kubernetes Dashboard can be accessed with the token you specified at deployment time. </p> <p>You can obtain statistics about the Kubernetes cluster: </p> </li> <li> <p>Terminating the OSCAR cluster</p> <p>You can terminate the OSCAR cluster from the IM Dashboard: </p> </li> </ol>"},{"location":"egi-integration/","title":"Integration with the EGI Federated Cloud","text":"<p>EGI is a federation of many cloud providers and hundreds of data centres, spread across Europe and worldwide that delivers advanced computing services to support scientists, multinational projects and research infrastructures.</p> <p>The EGI Federated Cloud is an IaaS-type cloud, made of academic private clouds and virtualised resources and built around open standards. Its development is driven by requirements of the scientific communities.</p>"},{"location":"egi-integration/#egi-applications-on-demand-im-dashboard","title":"EGI Applications on Demand: IM Dashboard","text":"<p>The OSCAR platform can be deployed on the EGI Federated Cloud resources through the IM Dashboard available in the EGI Applications on Demand service.</p> <p>The IM Dashboard documentation can be followed in order to deploy the platform.</p> <p></p>"},{"location":"egi-integration/#egi-datahub","title":"EGI DataHub","text":"<p>EGI DataHub, based on Onedata, provides a global data access solution for science. Integrated with the EGI AAI, it allows users to have Onedata spaces supported by providers across Europe for replicated storage and on-demand caching.</p> <p>EGI DataHub can be used as an output storage provider for OSCAR, allowing users to store the resulting files of their OSCAR services on a Onedata space. This can be done thanks to the FaaS Supervisor. Used in OSCAR and SCAR, responsible for managing the data Input/Output and the user code execution.</p> <p>To deploy a function with Onedata as output storage provider you only have to specify an identifier, the URL of the Oneprovider host, your access token and the name of your Onedata space in the \"Storage\" tab of the service creation wizard:</p> <p></p> <p>And the path where you want to store the files in the \"OUTPUTS\" tab:</p> <p></p> <p>This means that scientists can store their output files on their Onedata space in the EGI DataHub for long-time persistence and easy sharing of experimental results between researchers.</p>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Sometimes, when trying to deploy the cluster locally, it tells me that the :80 port is already in use.</li> </ul> <p>You may have a server running on the :80 port, such as Apache, while the deployment is trying to use it for the OSCAR UI. Restarting it would solve this problem.</p> <ul> <li>I get the following error message: \"Unable to communicate with the cluster. Please make sure that the endpoint is well-typed and accessible.\"</li> </ul> <p>When using oscar-cli, you can get this error if you try to run a service that is not present on the cluster set as default. You can check if you are using the correct default cluster with the following command,</p> <p><code>oscar-cli cluster default</code></p> <p>and set a new default cluster with the following command:</p> <p><code>oscar-cli cluster default -s CLUSTER_ID</code></p> <ul> <li>How do I use a secret image?</li> </ul> <p>In case it is required the use of secret images, you should create a secret with the docker login configuration with a structure like this:</p> <pre><code>apiVersion: v1\nkind: Secret\nmetadata:\n  name: dockersecret\n  namespace: oscar-svc\ndata:\n  .dockerconfigjson: {base64 .docker/config.json}\ntype: kubernetes.io/dockerconfigjson\n</code></pre> <p>Apply the file through kubectl into the Kubernetes OSCAR cluster to create the secret. To use it in OSCAR services, you must add the secret name (<code>dockersecret</code> in this example) in the definition of the service, using the API or a FDL, under the <code>image_pull_secrets</code> parameter, or through the \"Docker secret\" field in OSCAR-UI.</p>"},{"location":"fdl-composer/","title":"Functions Definition Language Composer","text":"<p>Writing an entire workflow in plain text could be a difficult task for many users. To simplify the process you can use FDL Composer, a web-based user interface to facilitate the definition of FDL YAML files for OSCAR and SCAR.</p> <p></p>"},{"location":"fdl-composer/#how-to-access-fdl-composer","title":"How to access FDl Composer","text":"<p>It does not require to be installed. Just access FDL Composer web. If you prefer to execute it on your computer instead of using the web, clone the git repository by using the following command:</p> <pre><code>git clone https://github.com/grycap/fdl-composer\n</code></pre> <p>And the run the app with <code>npm</code>:</p> <pre><code>npm start\n</code></pre>"},{"location":"fdl-composer/#basic-elements","title":"Basic elements","text":"<p>Workflows are composed of <code>OSCAR services</code> and <code>Storage providers</code>:</p>"},{"location":"fdl-composer/#oscar-services","title":"OSCAR services","text":"<p><code>OSCAR services</code> are responsible for processing the data uploaded to <code>Storage providers</code>.</p> <p>Defining a new <code>OSCAR service</code>  requires filling at least the <code>name</code>, <code>image</code>, and <code>script</code> fields.</p> <p>To define environment variables you must add them as a comma separated string of key=value entries. For example,  to create a variable with the name <code>firstName</code> and the value <code>John</code>, the \"Environment variables\" field should look like <code>firstName=John</code>. If you want to assign more than one variable, for example, <code>firstName</code> and <code>lastName</code> with the values <code>John</code> and <code>Keats</code>, the input field should include them all separated by commas (e.g., <code>firstName=John,lastName=Keats</code>).</p>"},{"location":"fdl-composer/#storage-providers-and-bucketsfolders","title":"Storage providers and buckets/folders","text":"<p><code>Storage providers</code> are object storage systems  responsible for storing both the input files to be processed by <code>OSCAR services</code> and the output files generated as a result of the processing.</p> <p>Three types of storage providers can be used in OSCAR FDLs: MinIO, Amazon S3, and OneData.</p> <p>To configure them, drag the storage provider from the menu to the canvas and double click on the item created. A window with a single input will appear. Then, insert the path of the folder name. To edit one of the storage providers, move the mouse over the item and select the edit option.</p> <p>Remember that only MinIO can be used as input storage provider for OSCAR services.</p>"},{"location":"fdl-composer/#download-and-load-state","title":"Download and load state","text":"<p>The graphic workflow can be saved in a file using the \"Download state\" button. OSCAR services, Storage Providers, and Buckets are kept in the file. The graphic workflow can be edited later by loading it with the \"Load state\" button.</p>"},{"location":"fdl-composer/#create-a-yaml-file","title":"Create a YAML file","text":"<p>You can easily download the workflow's FDL file (in YAML) through the \"Export  YAML\" button.</p>"},{"location":"fdl-composer/#connecting-components","title":"Connecting components","text":"<p>All components have four ports: The up and left ones are input ports while the right and down ports are used as output. <code>OSCAR Services</code> can only be connected with <code>Storage providers</code>, always linked in the same direction (the output of one element with the input of the other).</p> <p>When two services are connected, both will be declared in the FDL file, but they will work separately, and there will be no workflow between them. If two storage providers are connected between them, it will have no effect, but both storages will be declared.</p>"},{"location":"fdl-composer/#scar-options","title":"SCAR options","text":"<p>FDL Composer can also create FDL files for SCAR. This allows to define workflows that can be executed on the Edge or in on-premises Clouds through OSCAR, and on the public Cloud (AWS Lambda and/or AWS Batch) through SCAR.</p>"},{"location":"fdl-composer/#example","title":"Example","text":"<p>There is an example of fdl-composer implementing the video-process use case in our blog.</p>"},{"location":"fdl/","title":"Functions Definition Language (OSCAR)","text":"<p>Example:</p> <pre><code>functions:\n  oscar:\n  - oscar-test:\n      name: plants\n      memory: 2Gi\n      cpu: '1.0'\n      image: grycap/oscar-theano-plants\n      script: plants.sh\n      input:\n      - storage_provider: minio.default\n        path: example-workflow/in\n      output:\n      - storage_provider: minio.default\n        path: example-workflow/med\n  - oscar-test:\n      name: grayify\n      memory: 1Gi\n      cpu: '1.0'\n      image: grycap/imagemagick\n      script: grayify.sh\n      input:\n      - storage_provider: minio.default\n        path: example-workflow/med\n      output:\n      - storage_provider: minio.default\n        path: example-workflow/res\n      - storage_provider: onedata.my_onedata\n        path: result-example-workflow\n      - storage_provider: webdav.dcache\n        path: example-workflow/res\n\nstorage_providers:\n  onedata:\n    my_onedata:\n      oneprovider_host: my_provider.com\n      token: my_very_secret_token\n      space: my_onedata_space\n  webdav:\n    dcache:\n      hostname: my_dcache.com\n      login: my_username\n      password: my_password\n</code></pre>"},{"location":"fdl/#top-level-parameters","title":"Top level parameters","text":"Field Description <code>functions</code> Functions Mandatory parameter to define a Functions Definition Language file. Note that \"functions\" instead of \"services\" has been used in order to keep compatibility with SCAR <code>storage_providers</code> StorageProviders Parameter to define the credentials for the storage providers to be used in the services <code>clusters</code> map[string]Cluster configuration for the OSCAR clusters that can be used as service's replicas, being the key the user-defined identifier for the cluster. Optional"},{"location":"fdl/#functions","title":"Functions","text":"Field Description <code>oscar</code> map[string]Service array Main object with the definition of the OSCAR services to be deployed. The components of the array are Service maps, where the key of every service is the identifier of the cluster where the service (defined as the value of the entry on the map) will be deployed."},{"location":"fdl/#service","title":"Service","text":"Field Description <code>name</code> string The name of the service <code>cluster_id</code> string Identifier for the current cluster, used to specify the cluster's StorageProvider in job delegations. OSCAR-CLI sets it using the ClusterID from the FDL. Optional. (default: \"\") <code>image</code> string Docker image for the service <code>alpine</code> boolean Alpine parameter to set if image is based on Alpine. If <code>true</code> a custom release of faas-supervisor will be used. Optional (default: false) <code>script</code> string Local path to the user script to be executed in the service container <code>image_pull_secrets</code> string array Array of Kubernetes secrets. Only needed to use private images located on private registries. <code>memory</code> string Memory limit for the service following the kubernetes format. Optional (default: 256Mi) <code>cpu</code> string CPU limit for the service following the kubernetes format. Optional (default: 0.2) <code>enable_gpu</code> bool Parameter to enable the use of GPU for the service. Requires a device plugin deployed on the cluster (More info: Kubernetes device plugins). Optional (default: false) <code>total_memory</code> string Limit for the memory used by all the service's jobs running simultaneously. Apache YuniKorn scheduler is required to work. Same format as Memory, but internally translated to MB (integer). Optional (default: \"\") <code>total_cpu</code> string Limit for the virtual CPUs used by all the service's jobs running simultaneously. Apache YuniKorn scheduler is required to work. Same format as CPU, but internally translated to millicores (integer). Optional (default: \"\") <code>synchronous</code> SynchronousSettings Struct to configure specific sync parameters. This settings are only applied on Knative ServerlessBackend. Optional. <code>replicas</code> Replica array List of replicas to delegate jobs. Optional. <code>rescheduler_threshold</code> string Time (in seconds) that a job (with replicas) can be queued before delegating it. Optional. <code>log_level</code> string Log level for the FaaS Supervisor. Available levels: NOTSET, DEBUG, INFO, WARNING, ERROR and CRITICAL. Optional (default: INFO) <code>input</code> StorageIOConfig array Array with the input configuration for the service. Optional <code>output</code> StorageIOConfig array Array with the output configuration for the service. Optional <code>environment</code> EnvVarsMap The user-defined environment variables assigned to the service. Optional <code>annotations</code> map[string]string User-defined Kubernetes annotations to be set in job's definition. Optional <code>labels</code> map[string]string User-defined Kubernetes labels to be set in job's definition. Optional"},{"location":"fdl/#synchronoussettings","title":"SynchronousSettings","text":"Field Description <code>min_scale</code> integer Minimum number of active replicas (pods) for the service. Optional. (default: 0) <code>max_scale</code> integer Maximum number of active replicas (pods) for the service. Optional. (default: 0 (Unlimited))"},{"location":"fdl/#replica","title":"Replica","text":"Field Description <code>type</code> string Type of the replica to re-send events (can be <code>oscar</code> or <code>endpoint</code>) <code>cluster_id</code> string Identifier of the cluster as defined in the \"clusters\" FDL field. Only used if Type is <code>oscar</code> <code>service_name</code> string Name of the service in the replica cluster. Only used if Type is <code>oscar</code> <code>url</code> string URL of the endpoint to re-send events (HTTP POST). Only used if Type is <code>endpoint</code> <code>ssl_verify</code> boolean Parameter to enable or disable the verification of SSL certificates. Only used if Type is <code>endpoint</code>. Optional. (default: true) <code>priority</code> integer Priority value to define delegation priority. Highest priority is defined as 0. If a delegation fails, OSCAR will try to delegate to another replica with lower priority. Optional. (default: 0) <code>headers</code> map[string]string Headers to send in delegation requests. Optional"},{"location":"fdl/#storageioconfig","title":"StorageIOConfig","text":"Field Description <code>storage_provider</code> string Reference to the storage provider defined in storage_providers. This string is composed by the provider's name (minio, s3, onedata) and identifier (defined by the user), separated by a point (e.g. \"minio.myidentifier\") <code>path</code> string Path in the storage provider. In MinIO and S3 the first directory of the specified path is translated into the bucket's name (e.g. \"bucket/folder/subfolder\") <code>suffix</code> string array Array of suffixes for filtering the files to be uploaded. Only used in the <code>output</code> field. Optional <code>prefix</code> string array Array of prefixes for filtering the files to be uploaded. Only used in the <code>output</code> field. Optional"},{"location":"fdl/#envvarsmap","title":"EnvVarsMap","text":"Field Description <code>Variables</code> map[string]string Map to define the environment variables that will be available in the service container"},{"location":"fdl/#storageproviders","title":"StorageProviders","text":"Field Description <code>minio</code> map[string]MinIOProvider Map to define the credentials for a MinIO storage provider, being the key the user-defined identifier for the provider <code>s3</code> map[string]S3Provider Map to define the credentials for a Amazon S3 storage provider, being the key the user-defined identifier for the provider <code>onedata</code> map[string]OnedataProvider Map to define the credentials for a Onedata storage provider, being the key the user-defined identifier for the provider <code>webdav</code> map[string]WebDavProvider Map to define the credentials for a storage provider accesible via WebDav protocol, being the key the user-defined identifier for the provider"},{"location":"fdl/#cluster","title":"Cluster","text":"Field Description <code>endpoint</code>string Endpoint of the OSCAR cluster API <code>auth_user</code>string Username to connect to the cluster (basic auth) <code>auth_password</code>string Password to connect to the cluster (basic auth) <code>ssl_verify</code>boolean Parameter to enable or disable the verification of SSL certificates"},{"location":"fdl/#minioprovider","title":"MinIOProvider","text":"Field Description <code>endpoint</code> string MinIO endpoint <code>verify</code> bool Verify MinIO's TLS certificates for HTTPS connections <code>access_key</code> string Access key of the MinIO server <code>secret_key</code> string Secret key of the MinIO server <code>region</code> string Region of the MinIO server"},{"location":"fdl/#s3provider","title":"S3Provider","text":"Field Description <code>access_key</code> string Access key of the AWS S3 service <code>secret_key</code> string Secret key of the AWS S3 service <code>region</code> string Region of the AWS S3 service"},{"location":"fdl/#onedataprovider","title":"OnedataProvider","text":"Field Description <code>oneprovider_host</code> string Endpoint of the Oneprovider <code>token</code> string Onedata access token <code>space</code> string Name of the Onedata space"},{"location":"fdl/#webdavprovider","title":"WebDAVProvider","text":"Field Description <code>hostname</code> string Provider hostname <code>login</code> string Provider account username <code>password</code> string Provider account password"},{"location":"invoking/","title":"Invoking services","text":"<p>OSCAR services can be invoked synchronously and asynchronously sending an HTTP POST request to paths <code>/run/&lt;SERVICE_NAME&gt;</code> and <code>/job/&lt;SERVICE_NAME&gt;</code> respectively. For file processing, OSCAR automatically manages the creation and notification system of MinIO buckets in order to allow the event-driven invocation of services using asynchronous requests, generating a Kubernetes job for every file to be processed.</p>"},{"location":"invoking/#service-access-tokens","title":"Service access tokens","text":"<p>As detailed in the API specification, invocation paths require the service access token in the request header for authentication. Service access tokens are auto-generated in service creation and update, and MinIO eventing system is automatically configured to use them for event-driven file processing. Tokens can be obtained through the API, using the <code>oscar-cli service get</code> command or directly from the web interface.</p> <p></p>"},{"location":"invoking/#synchronous-invocations","title":"Synchronous invocations","text":"<p>Synchronous invocations allow obtaining the execution output as the response to the HTTP call to the <code>/run/&lt;SERVICE_NAME&gt;</code> path. For this, OSCAR delegates the execution to a Serverless Backend (Knative or OpenFaaS). Unlike asynchronous invocations, that are translated into Kubernetes jobs, synchronous invocations use a \"function\" pod to handle requests. This is possible thanks to the OpenFaaS Watchdog, which is injected into each service and is in charge of forking the process to be executed for each request received.</p> <p></p> <p>Synchronous invocations can be made through OSCAR-CLI, using the comand <code>oscar-cli service run</code>:</p> <pre><code>oscar-cli service run [SERVICE_NAME] {--input | --text-input} {-o | -output }\n</code></pre> <p>You can check these use-cases:</p> <ul> <li>plant-classification-sync</li> <li>text-to-speech.</li> </ul> <p>The input can be sent as a file via the <code>--input</code> flag, and the result of the execution will be displayed directly in the terminal:</p> <pre><code>oscar-cli service run plant-classification-sync --input images/image3.jpg\n</code></pre> <p>Alternatively, it can be sent as plain text using the <code>--text-input</code> flag and the result stored in a file using the <code>--output</code> flag:</p> <pre><code>oscar-cli service run text-to-speech --text-input \"Hello everyone\"  --output output.mp3\n</code></pre>"},{"location":"invoking/#inputoutput","title":"Input/Output","text":"<p>FaaS Supervisor, the component in charge of managing the input and output of services, allows JSON or base64 encoded body in service requests. The body of these requests will be automatically decoded into the invocation's input file available from the script through the <code>$INPUT_FILE_PATH</code> environment variable.</p> <p>The output of synchronous invocations will depend on the application itself:</p> <ol> <li>If the script generates a file inside the output dir available through the     <code>$TMP_OUTPUT_DIR</code> environment variable, the result will be the file encoded in     base64.</li> <li>If the script generates more than one file inside <code>$TMP_OUTPUT_DIR</code>, the     result will be a zip archive containing all files encoded in base64.</li> <li>If there are no files in <code>$TMP_OUTPUT_DIR</code>, FaaS Supervisor will return its     logs, including the stdout of the user script run.     To avoid FaaS Supervisor's logs, you must set the service's <code>log_level</code>     to <code>CRITICAL</code>.</li> </ol> <p>This way users can adapt OSCAR's services to their own needs.</p>"},{"location":"invoking/#oscar-cli","title":"OSCAR-CLI","text":"<p>OSCAR-CLI simplifies the execution of services synchronously via the <code>oscar-cli service run</code> command. This command requires the input to be passed as text through the <code>--text-input</code> flag or directly a file to be sent by passing its path through the <code>--input</code> flag. Both input types are automatically encoded in base64.</p> <p>It also allow setting the <code>--output</code> flag to indicate a path for storing (and decoding if needed) the output body in a file, otherwise the output will be shown in stdout.</p> <p>An illustration of triggering a service synchronously through OSCAR-CLI can be found in the cowsay example.</p> <pre><code>oscar-cli service run cowsay --text-input '{\"message\":\"Hello World\"}'\n</code></pre>"},{"location":"invoking/#curl","title":"cURL","text":"<p>Naturally, OSCAR services can also be invoked via traditional HTTP clients such as cURL via the path <code>/run/&lt;SERVICE_NAME&gt;</code>. However, you must take care to properly format the input to one of the two supported formats (JSON or base64 encoded) and include the service access token in the request.</p> <p>An illustration of triggering a service synchronously through cURL can be found in the cowsay example.</p> <p>To send an input file through cURL, you must encode it in base64. To avoid issues with the output in synchronous invocations remember to put the <code>log_level</code> as <code>CRITICAL</code>. Output, which is encoded in base64, should be decoded as well. Save output in the expected format of the use-case.</p> <pre><code>base64 input.png | curl -X POST -H \"Authorization: Bearer &lt;TOKEN&gt;\" \\\n -d @- https://&lt;CLUSTER_ENDPOINT&gt;/run/&lt;OSCAR_SERVICE&gt; | base64 -d &gt; result.png\n</code></pre>"},{"location":"invoking/#limitations","title":"Limitations","text":"<p>Although the use of the Knative Serverless Backend for synchronous invocations provides elasticity similar to the one provided by their counterparts in public clouds, such as AWS Lambda, synchronous invocations are not still the best option to run long-running resource-demanding applications, like deep learning inference or video processing. </p> <p>The synchronous invocation of long-running resource-demanding applications may lead to timeouts on Knative pods. Therefore, we consider Kubernetes job generation as the optimal approach to handle event-driven file processing through asynchronous invocations in OSCAR, being the execution of synchronous services a convenient way to support general lightweight container-based applications.</p>"},{"location":"license/","title":"License","text":"<pre><code>                                 Apache License\n\n                           Version 2.0, January 2004\n\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"{}\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright 2018 GRyCAP - I3M - UPV\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n</code></pre>"},{"location":"local-testing/","title":"Local Testing with kind","text":"<p>The easiest way to test the OSCAR platform locally is using kind. Kind allows the deployment of Kubernetes clusters inside Docker containers and automatically configures <code>kubectl</code> to access them.</p>"},{"location":"local-testing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker, required by kind to launch   the Kubernetes nodes on containers.</li> <li>Kubectl to   communicate with the Kubernetes cluster.</li> <li>Helm to easily deploy applications on Kubernetes.</li> <li>Kind to   deploy the local Kubernetes cluster.</li> </ul> <p>Other prerequisites</p> <ul> <li> <p>Although the use of local Docker images has yet to be implemented as a feature on OSCAR clusters, the local deployment for testing allows you to use a local Docker registry to use this kind of images.  The registry uses by default the port 5001, so each image you want to use must be tagged as <code>localhost:5001/[image_name]</code> and pushed to the repository through the <code>docker push localhost:5001/[image_name]</code> command.</p> </li> <li> <p>Port 80 must be available to avoid errors during the deployment since OSCAR-UI uses it. Check Frequently Asked Questions (FAQ) for more info.</p> </li> </ul>"},{"location":"local-testing/#automated-local-testing","title":"Automated local testing","text":"<p>To set up the enviroment for the platform testing you can run the following command. This script automatically executes all the necessary steps to deploy the local cluster and the OSCAR platform along with all the required tools. </p> <pre><code>curl -sSL http://go.oscar.grycap.net | bash\n</code></pre>"},{"location":"local-testing/#steps-for-manual-local-testing","title":"Steps for manual local testing","text":"<p>If you want to do it manualy you can follow the listed steps.</p>"},{"location":"local-testing/#create-the-cluster","title":"Create the cluster","text":"<p>To create a single node cluster with MinIO and Ingress controller ports locally accessible, run:</p> <pre><code>cat &lt;&lt;EOF | kind create cluster --config=-\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nnodes:\n- role: control-plane\n  kubeadmConfigPatches:\n  - |\n    kind: InitConfiguration\n    nodeRegistration:\n      kubeletExtraArgs:\n        node-labels: \"ingress-ready=true\"\n  extraPortMappings:\n  - containerPort: 80\n    hostPort: 80\n    protocol: TCP\n  - containerPort: 443\n    hostPort: 443\n    protocol: TCP\n  - containerPort: 30300\n    hostPort: 30300\n    protocol: TCP\n  - containerPort: 30301\n    hostPort: 30301\n    protocol: TCP\nEOF\n</code></pre>"},{"location":"local-testing/#deploy-nginx-ingress","title":"Deploy NGINX Ingress","text":"<p>To enable Ingress support for accessing the OSCAR server, we must deploy the NGINX Ingress:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/static/provider/kind/deploy.yaml\n</code></pre>"},{"location":"local-testing/#deploy-minio","title":"Deploy MinIO","text":"<p>OSCAR depends on MinIO as a storage provider and function trigger. The easy way to run MinIO in a Kubernetes cluster is by installing its helm chart. To  install the helm MinIO repo and install the chart, run the following commands replacing <code>&lt;MINIO_PASSWORD&gt;</code> with a password. It must have at least 8 characters:</p> <pre><code>helm repo add minio https://charts.min.io\nhelm install minio minio/minio --namespace minio --set rootUser=minio,\\\nrootPassword=&lt;MINIO_PASSWORD&gt;,service.type=NodePort,service.nodePort=30300,\\\nconsoleService.type=NodePort,consoleService.nodePort=30301,mode=standalone,\\\nresources.requests.memory=512Mi,\\\nenvironment.MINIO_BROWSER_REDIRECT_URL=http://localhost:30301 \\\n --create-namespace\n</code></pre> <p>Note that the deployment has been configured to use the rootUser <code>minio</code> and the specified password as rootPassword. The NodePort service type has been used in order to allow access from <code>http://localhost:30300</code> (API) and <code>http://localhost:30301</code> (Console).</p>"},{"location":"local-testing/#deploy-nfs-server-provisioner","title":"Deploy NFS server provisioner","text":"<p>NFS server provisioner is required for the creation of <code>ReadWriteMany</code> PersistentVolumes in the kind cluster. This is needed by the OSCAR services to mount the volume with the FaaS Supervisor inside the job containers.</p> <p>To deploy it you can use this chart executing:</p> <pre><code>helm repo add nfs-ganesha-server-and-external-provisioner https://kubernetes-sigs.github.io/nfs-ganesha-server-and-external-provisioner/\nhelm install nfs-server-provisioner nfs-ganesha-server-and-external-provisioner/nfs-server-provisioner\n</code></pre> <p>Some Linux distributions may have problems using the NFS server provisioner with kind due to its default configuration of kernel-limit file descriptors. To workaround it, please run <code>sudo sysctl -w fs.nr_open=1048576</code>.</p>"},{"location":"local-testing/#deploy-knative-serving-as-serverless-backend-optional","title":"Deploy Knative Serving as Serverless Backend (OPTIONAL)","text":"<p>OSCAR supports Knative Serving as Serverless Backend to process synchronous invocations. If you want to deploy it in the kind cluster, first you must deploy the Knative Operator</p> <pre><code>kubectl apply -f https://github.com/knative/operator/releases/download/knative-v1.3.1/operator.yaml\n</code></pre> <p>Note that the above command deploys the version <code>v1.3.1</code> of the Operator. You can check if there are new versions here.</p> <p>Once the Operator has been successfully deployed, you can install the Knative Serving stack with the following command:</p> <pre><code>cat &lt;&lt;EOF | kubectl apply -f -\n---\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: knative-serving\n---\napiVersion: operator.knative.dev/v1beta1\nkind: KnativeServing\nmetadata:\n  name: knative-serving\n  namespace: knative-serving\nspec:\n  version: 1.3.0\n  ingress:\n    kourier:\n      enabled: true\n      service-type: ClusterIP\n  config:\n    config-features:\n      kubernetes.podspec-persistent-volume-claim: enabled\n      kubernetes.podspec-persistent-volume-write: enabled\n    network:\n      ingress-class: \"kourier.ingress.networking.knative.dev\"\nEOF\n</code></pre>"},{"location":"local-testing/#deploy-oscar","title":"Deploy OSCAR","text":"<p>First, create the <code>oscar</code> and <code>oscar-svc</code> namespaces by executing:</p> <pre><code>kubectl apply -f https://raw.githubusercontent.com/grycap/oscar/master/deploy/yaml/oscar-namespaces.yaml\n</code></pre> <p>Then, add the grycap helm repo and deploy by running the following commands replacing <code>&lt;OSCAR_PASSWORD&gt;</code> with a password of your choice and <code>&lt;MINIO_PASSWORD&gt;</code> with the MinIO rootPassword, and remember to add the flag <code>--set serverlessBackend=knative</code> if you deployed it in the previous step:</p> <pre><code>helm repo add grycap https://grycap.github.io/helm-charts/\nhelm install --namespace=oscar oscar grycap/oscar \\\n --set authPass=&lt;OSCAR_PASSWORD&gt; --set service.type=ClusterIP \\\n --set ingress.create=true --set volume.storageClassName=nfs \\\n --set minIO.endpoint=http://minio.minio:9000 --set minIO.TLSVerify=false \\\n --set minIO.accessKey=minio --set minIO.secretKey=&lt;MINIO_PASSWORD&gt;\n</code></pre> <p>Now you can access to the OSCAR web interface through <code>https://localhost</code> with user <code>oscar</code> and the specified password.</p> <p>Note that the OSCAR server has been configured to use the ClusterIP service of MinIO for internal communication. This blocks the MinIO section in the OSCAR web interface, so to download and upload files you must connect directly to MinIO (<code>http://localhost:30300</code>).</p>"},{"location":"local-testing/#delete-the-cluster","title":"Delete the cluster","text":"<p>Once you have finished testing the platform, you can remove the local kind cluster by executing:</p> <pre><code>kind delete cluster\n</code></pre> <p>Remember that if you have more than one cluster created, it may be required to set the <code>--name</code> flag to specify the name of the cluster to be deleted.</p>"},{"location":"local-testing/#using-oscar-cli","title":"Using OSCAR-CLI","text":"<p>To use OSCAR-CLI in a local deployment, you should set the <code>--disable-ssl</code> flag to disable verification of the self-signed certificates:</p> <pre><code>oscar-cli cluster add oscar-cluster https://localhost oscar &lt;OSCAR_PASSWORD&gt; --disable-ssl\n</code></pre>"},{"location":"minio-bucket-replication/","title":"MinIO bucket replication","text":"<p>In scenarios where you have two linked OSCAR clusters as part of the same workflow defined in FDL, temporary network disconnections cause that data generated on the first cluster during the disconnection time is lost as well. </p> <p>To resolve this scenario we propose the use of replicated buckets on MinIO. With this approach, you can have two buckets synchronized on different OSCAR clusters so that, if the connection is lost, they will be re-synchronized when the connection is restored.</p> <p>An example of this scenario is shown on the following diagram, where there are two MinIO instances (each one on a different OSCAR cluster), and the output of the execution of service_x on the source serves as input for the service_y on the remote cluster.</p> <p></p> <p>Here is in more detail the data flow between the buckets:</p> <p>MinIO instance source</p> <ul> <li><code>input</code>: receives data and triggers the execution of OSCAR service_x.</li> <li><code>intermediate</code>: the output files from service_x are stored on this bucket and synchronized with the intermediate bucket on the remote instance. </li> </ul> <p>MinIO instance remote</p> <ul> <li><code>intermediate</code>: the synchronized bucket that stores the replicated data and triggers OSCAR service_y.</li> <li><code>output</code>: stores the output files of service_y.</li> </ul>"},{"location":"minio-bucket-replication/#considerations","title":"Considerations","text":"<p>When you create the service on the remote OSCAR cluster, the <code>intermediate</code> bucket which is both the replica and input of the OSCAR service will have the webhook event for PUT actions enabled so it can trigger the OSCAR service.</p> <p>Because, as explained below on Event handling on replication events, there are some specific events for replicated buckets, it is important to delete this event webhook to avoid getting both events every time.</p> <pre><code>mc event remove originminio/intermediate arn:aws:sqs::intermediate:webhook --event put\n</code></pre>"},{"location":"minio-bucket-replication/#helm-installation","title":"Helm installation","text":"<p>To be able to use replication each MinIO instance deployed with Helm has to be configured in distributed mode. This is done by adding the parameters <code>mode=distributed,replicas=NUM_REPLICAS</code>.</p> <p>Here is an example of a local MinIO replicated deployment with Helm:</p> <pre><code>helm install minio minio/minio --namespace minio --set rootUser=minio,rootPassword=minio123,service.type=NodePort,service.nodePort=30300,consoleService.type=NodePort,consoleService.nodePort=30301,mode=distributed,replicas=2,resources.requests.memory=512Mi,environment.MINIO_BROWSER_REDIRECT_URL=http://localhost:30301 --create-namespace\n</code></pre>"},{"location":"minio-bucket-replication/#minio-setup","title":"MinIO setup","text":"<p>To use the replication service it is necessary to set up manually both the requirements and the replication, either by command line or via the MinIO console. We created a test environment with replication via the command line as follows.</p> <p>First, we define our minIO instances (<code>originminio</code> and <code>remoteminio</code>) on the minio client.</p> <pre><code>mc alias set originminio https://localminio minioadminuser minioadminpassword\n\nmc alias set remoteminio https://remoteminio minioadminuser minioadminpassword\n</code></pre> <p>A requisite for replication is to enable the versioning on the buckets that will serve as origin and replica. When we create a service through OSCAR and the minIO buckets are created, versioning is not enabled by default, so we have to do it manually.</p> <pre><code>mc version enable originminio/intermediate\n\nmc version enable remoteminio/intermediate\n</code></pre> <p>Then, you can create the replication remote target</p> <pre><code>mc admin bucket remote add originminio/intermediate \\\n  https://RemoteUser:Password@HOSTNAME/intermediate \\\n  --service \"replication\"\n</code></pre> <p>and add the bucket replication rule so the actions on the origin bucket get synchronized on the replica.</p> <pre><code>mc replicate add originminio/intermediate \\\n   --remote-bucket 'arn:minio:replication::&lt;UUID&gt;:intermediate' \\\n   --replicate \"delete,delete-marker,existing-objects\"\n</code></pre>"},{"location":"minio-bucket-replication/#event-handling-on-replication-events","title":"Event handling on replication events","text":"<p>Once you have replica instances you can add a specific event webhook for the replica-related events.</p> <pre><code>mc event add originminio/intermediate arn:minio:sqs::intermediate:webhook --event replica\n</code></pre> <p>The replication events sometimes arrive duplicated. Although this is not yet implemented, a solution to the duplicated events would be to filter them by the <code>userMetadata</code>, which is marked as \"PENDING\" on the events to be discarded.</p> <pre><code>  \"userMetadata\": {\n    \"X-Amz-Replication-Status\": \"PENDING\"\n  }\n</code></pre> <p>MinIO documentation used</p> <ul> <li>Requirements to Set Up Bucket Replication</li> <li>Enable One-Way Server-Side Bucket Replication</li> </ul>"},{"location":"oidc-auth/","title":"OpenID Connect Authorization","text":"<p>OSCAR REST API supports OIDC (OpenID Connect) access tokens to authorize users since release <code>v2.5.0</code>. By default, OSCAR clusters deployed via the IM Dashboard are configured to allow authorization via basic auth and OIDC tokens using the EGI Check-in issuer. From the IM Dashboard deployment window, users can add one EGI Virtual Organization to grant access for all users from that VO.</p> <p></p>"},{"location":"oidc-auth/#accessing-from-oscar-ui","title":"Accessing from OSCAR-UI","text":"<p>The static web interface of OSCAR has been integrated with EGI Check-in and published in ui.oscar.grycap.net to facilitate the authorization of users. To login through EGI Check\u00edn using OIDC tokens, users only have to put the endpoint of its OSCAR cluster and click on the \"EGI CHECK-IN\" button.</p> <p></p>"},{"location":"oidc-auth/#integration-with-oscar-cli-via-oidc-agent","title":"Integration with OSCAR-CLI via OIDC Agent","text":"<p>Since version <code>v1.4.0</code> OSCAR-CLI supports API authorization via OIDC tokens thanks to the integration with oidc-agent.</p> <p>Users must install the oidc-agent following its instructions and create a new account configuration for the <code>https://aai.egi.eu/auth/realms/egi/</code> issuer. After that, clusters can be added with the command <code>oscar-cli cluster add</code> specifying the oidc-agent account name with the <code>--oidc-account-name</code> flag.</p>"},{"location":"oscar-cli/","title":"OSCAR-CLI","text":"<p>OSCAR-CLI provides a command line interface to interact with OSCAR clusters in a simple way. It supports service management, workflows definition from FDL (Functions Definition Language) files and the ability to manage files from OSCAR's compatible storage providers (MinIO, AWS S3 and Onedata). The folder <code>example-workflow</code> contains all the necessary files to create a simple workflow to test the tool.</p>"},{"location":"oscar-cli/#download","title":"Download","text":""},{"location":"oscar-cli/#releases","title":"Releases","text":"<p>The easy way to download OSCAR-CLI is through the github releases page. There are binaries for multiple platforms and OS. If you need a binary for another platform, please open an issue.</p>"},{"location":"oscar-cli/#install-from-source","title":"Install from source","text":"<p>If you have go installed and configured, you can get it from source directly by executing:</p> <pre><code>go install github.com/grycap/oscar-cli@latest\n</code></pre>"},{"location":"oscar-cli/#available-commands","title":"Available commands","text":"<ul> <li>apply</li> <li>cluster</li> <li>add</li> <li>default</li> <li>info</li> <li>list</li> <li>remove</li> <li>service</li> <li>get</li> <li>list</li> <li>remove</li> <li>run</li> <li>logs list</li> <li>logs get</li> <li>logs remove</li> <li>get-file</li> <li>put-file</li> <li>list-files</li> <li>version</li> <li>help</li> </ul>"},{"location":"oscar-cli/#apply","title":"apply","text":"<p>Apply a FDL file to create or edit services in clusters.</p> <pre><code>Usage:\n  oscar-cli apply FDL_FILE [flags]\n\nAliases:\n  apply, a\n\nFlags:\n      --config string   set the location of the config file (YAML or JSON)\n  -h, --help            help for apply\n</code></pre>"},{"location":"oscar-cli/#cluster","title":"cluster","text":"<p>Manages the configuration of clusters.</p>"},{"location":"oscar-cli/#subcommands","title":"Subcommands","text":""},{"location":"oscar-cli/#add","title":"add","text":"<p>Add a new existing cluster to oscar-cli.</p> <pre><code>Usage:\n  oscar-cli cluster add IDENTIFIER ENDPOINT {USERNAME {PASSWORD | \\\n  --password-stdin} | --oidc-account-name ACCOUNT} [flags]\n\nAliases:\n  add, a\n\nFlags:\n      --disable-ssl               disable verification of ssl certificates for the\n                                  added cluster\n  -h, --help                      help for add\n  -o, --oidc-account-name string  OIDC account name to authenticate using\n                                  oidc-agent. Note that oidc-agent must be\n                                  started and properly configured\n                                  (See:https://indigo-dc.gitbook.io/oidc-agent/)\n      --password-stdin            take the password from stdin\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#default","title":"default","text":"<p>Show or set the default cluster.</p> <pre><code>Usage:\n  oscar-cli cluster default [flags]\n\nAliases:\n  default, d\n\nFlags:\n  -h, --help         help for default\n  -s, --set string   set a default cluster by passing its IDENTIFIER\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#info","title":"info","text":"<p>Show information of an OSCAR cluster.</p> <pre><code>Usage:\n  oscar-cli cluster info [flags]\n\nAliases:\n  info, i\n\nFlags:\n  -c, --cluster string   set the cluster\n  -h, --help             help for info\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#list","title":"list","text":"<p>List the configured OSCAR clusters.</p> <pre><code>Usage:\n  oscar-cli cluster list [flags]\n\nAliases:\n  list, ls\n\nFlags:\n  -h, --help   help for list\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#remove","title":"remove","text":"<p>Remove a cluster from the configuration file.</p> <pre><code>Usage:\n  oscar-cli cluster remove IDENTIFIER [flags]\n\nAliases:\n  remove, rm\n\nFlags:\n  -h, --help   help for remove\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#service","title":"service","text":"<p>Manages the services within a cluster.</p>"},{"location":"oscar-cli/#subcommands-of-services","title":"Subcommands of services","text":""},{"location":"oscar-cli/#get","title":"get","text":"<p>Get the definition of a service.</p> <pre><code>Usage:\n  oscar-cli service get SERVICE_NAME [flags]\n\nAliases:\n  get, g\n\nFlags:\n  -c, --cluster string   set the cluster\n  -h, --help             help for get\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#list-services","title":"list services","text":"<p>List the available services in a cluster.</p> <pre><code>Usage:\n  oscar-cli service list [flags]\n\nAliases:\n  list, ls\n\nFlags:\n  -c, --cluster string   set the cluster\n  -h, --help             help for list\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#remove-services","title":"remove services","text":"<p>Remove a service from the cluster.</p> <pre><code>Usage:\n  oscar-cli service remove SERVICE_NAME... [flags]\n\nAliases:\n  remove, rm\n\nFlags:\n  -c, --cluster string   set the cluster\n  -h, --help             help for remove\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#run","title":"run","text":"<p>Invoke a service synchronously (a Serverless backend in the cluster is required).</p> <pre><code>Usage:\n  oscar-cli service run SERVICE_NAME {--input | --text-input} [flags]\n\nAliases:\n  run, invoke, r\n\nFlags:\n  -c, --cluster string      set the cluster\n  -h, --help                help for run\n  -i, --input string        input file for the request\n  -o, --output string       file path to store the output\n  -t, --text-input string   text input string for the request\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#logs-list","title":"logs list","text":"<p>List the logs from a service.</p> <pre><code>Usage:\n  oscar-cli service logs list SERVICE_NAME [flags]\n\nAliases:\n  list, ls\n\nFlags:\n  -h, --help             help for list\n  -s, --status strings   filter by status (Pending, Running, Succeeded or\n                         Failed), multiple values can be specified by a\n                         comma-separated string\n\nGlobal Flags:\n  -c, --cluster string   set the cluster\n      --config string    set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#logs-get","title":"logs get","text":"<p>Get the logs from a service's job.</p> <pre><code>Usage:\n  oscar-cli service logs get SERVICE_NAME JOB_NAME [flags]\n\nAliases:\n  get, g\n\nFlags:\n  -h, --help              help for get\n  -t, --show-timestamps   show timestamps in the logs\n\nGlobal Flags:\n  -c, --cluster string   set the cluster\n      --config string    set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#logs-remove","title":"logs remove","text":"<p>Remove a service's job along with its logs.</p> <pre><code>Usage:\n  oscar-cli service logs remove SERVICE_NAME \\\n   {JOB_NAME... | --succeeded | --all} [flags]\n\nAliases:\n  remove, rm\n\nFlags:\n  -a, --all         remove all logs from the service\n  -h, --help        help for remove\n  -s, --succeeded   remove succeeded logs from the service\n\nGlobal Flags:\n  -c, --cluster string   set the cluster\n      --config string    set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#get-file","title":"get-file","text":"<p>Get a file from a service's storage provider.</p> <p>The STORAGE_PROVIDER argument follows the format STORAGE_PROVIDER_TYPE.STORAGE_PROVIDER_NAME, being the STORAGE_PROVIDER_TYPE one of the three supported storage providers (MinIO, S3 or Onedata) and the STORAGE_PROVIDER_NAME is the identifier for the provider set in the service's definition.</p> <pre><code>Usage:\n  oscar-cli service get-file SERVICE_NAME STORAGE_PROVIDER REMOTE_FILE \\\n   LOCAL_FILE [flags]\n\nAliases:\n  get-file, gf\n\nFlags:\n  -c, --cluster string   set the cluster\n  -h, --help             help for get-file\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#put-file","title":"put-file","text":"<p>Put a file in a service's storage provider.</p> <p>The STORAGE_PROVIDER argument follows the format STORAGE_PROVIDER_TYPE.STORAGE_PROVIDER_NAME, being the STORAGE_PROVIDER_TYPE one of the three supported storage providers (MinIO, S3 or Onedata) and the STORAGE_PROVIDER_NAME is the identifier for the provider set in the service's definition.</p> <pre><code>Usage:\n  oscar-cli service put-file SERVICE_NAME STORAGE_PROVIDER LOCAL_FILE \\\n   REMOTE_FILE [flags]\n\nAliases:\n  put-file, pf\n\nFlags:\n  -c, --cluster string   set the cluster\n  -h, --help             help for put-file\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#list-files","title":"list-files","text":"<p>List files from a service's storage provider path.</p> <p>The STORAGE_PROVIDER argument follows the format STORAGE_PROVIDER_TYPE.STORAGE_PROVIDER_NAME, being the STORAGE_PROVIDER_TYPE one of the three supported storage providers (MinIO, S3 or Onedata) and the STORAGE_PROVIDER_NAME is the identifier for the provider set in the service's definition.</p> <pre><code>Usage:\n  oscar-cli service list-files SERVICE_NAME STORAGE_PROVIDER REMOTE_PATH [flags]\n\nAliases:\n  list-files, list-file, lsf\n\nFlags:\n  -c, --cluster string   set the cluster\n  -h, --help             help for list-files\n\nGlobal Flags:\n      --config string   set the location of the config file (YAML or JSON)\n</code></pre>"},{"location":"oscar-cli/#version","title":"version","text":"<p>Print the version.</p> <pre><code>Usage:\n  oscar-cli version [flags]\n\nAliases:\n  version, v\n\nFlags:\n  -h, --help   help for version\n</code></pre>"},{"location":"oscar-cli/#help","title":"help","text":"<p>Help provides help for any command in the application. Simply type oscar-cli help [path to command] for full details.</p> <pre><code>Usage:\n  oscar-cli help [command] [flags]\n\nFlags:\n  -h, --help   help for help\n</code></pre>"},{"location":"usage/","title":"Using OSCAR through the web-based UI","text":"<p>OSCAR allows the creation of serverless file-processing services based on container images. These services require a user-defined script with the commands responsible of the processing. The platform automatically mounts a volume on the containers with the FaaS Supervisor component, which is in charge of:</p> <ul> <li>Downloading the file that invokes the service and make it accessible through     the <code>INPUT_FILE_PATH</code> environment variable.</li> <li>Execute the user-defined script.</li> <li>Upload the content of the output folder accessible via the <code>TMP_OUTPUT_DIR</code>     environment variable.</li> </ul> <p>You can follow one of the examples in order to test the OSCAR framework for specific applications. We recommend you to start with the plant classification example detailed below.</p> <p>If you prefer to use the command-line interface rather than the web-based UI, there is an example in oscar-cli's repository.</p>"},{"location":"usage/#login","title":"Login","text":"<p>OSCAR is exposed via a Kubernetes ingress and it is accessible via the Kubernetes master node IP. If you deployed it using EC3 you can find the credentials here.</p> <p></p> <p>After a correct login, you should see the main view:</p> <p></p>"},{"location":"usage/#deploying-services","title":"Deploying services","text":"<p>In order to create a new service, you must click on the \"DEPLOY NEW SERVICE\" button and follow the wizard. Remember that a script must be provided for the processing of files. This script must use the environment variables <code>INPUT_FILE_PATH</code> and <code>TMP_OUTPUT_DIR</code> to refer to the input file and the folder where to save the results respectively:</p> <pre><code>#!/bin/bash\n\necho \"SCRIPT: Invoked classify_image.py. File available in $INPUT_FILE_PATH\"\nFILE_NAME=`basename \"$INPUT_FILE_PATH\"`\nOUTPUT_FILE=\"$TMP_OUTPUT_DIR/$FILE_NAME\"\npython2 /opt/plant-classification-theano/classify_image.py \\\n \"$INPUT_FILE_PATH\" -o \"$OUTPUT_FILE\"\n</code></pre> <p>You must fill in the fields indicating the container image to use, the name of the service and the script file. In addition, you can add environment variables, specify the resources (RAM and CPUs) and choose the log level of the service.</p> <p>Note that specifying a tag in the container image used can be convenient to avoid problems with quotas for certain container registries such as Docker Hub. This is due to the fact that Kubernetes defaults the <code>imagePullPolicy</code> of pods to <code>Always</code> when no tag or the <code>latest</code> tag is set, which checks the version of the image in the registry every time a job is launched.</p> <p></p> <p>Next, the credentials of the storage providers to be used must be introduced. As the platform already has a MinIO deployment to operate, it is not necessary to enter its credentials for using it.</p> <p>Multiple MinIO, Onedata and Amazon S3 storage providers can be used. Remember to click the \"ADD\" button after completing each one.</p> <p></p> <p>Then, click the \"NEXT\" button to go to the last section of the wizard.</p> <p></p> <p>In this section, you must first choose the paths of the storage provider to be used as source of events, i.e. the input bucket and/or folder that will trigger the service.</p> <p>Only the <code>minio.default</code> provider can be used as input storage provider.</p> <p></p> <p>After filling in each path, remember to click on the \"ADD INPUT\" button.</p> <p></p> <p>Finally, the same must be done to indicate the output paths to be used in the desired storage providers. You can also indicate suffixes and/or prefixes to filter the files uploaded to each path by name.</p> <p></p> <p>The resulting files can be stored in several storage providers, like in the following example, where they are stored in the MinIO server of the platform and in a Onedata space provided by the user.</p> <p></p> <p>After clicking the \"SUBMIT\" button the new service will appear in the main view after a few seconds.</p> <p></p>"},{"location":"usage/#triggering-the-service","title":"Triggering the service","text":""},{"location":"usage/#http-endpoints","title":"HTTP endpoints","text":"<p>OSCAR services can be invoked through auto-generated HTTP endpoints. Requests to these endpoints can be made in two ways:</p> <ul> <li>Synchronous through the path <code>/run/&lt;SERVICE_NAME&gt;</code>. This redirects the     request to the OpenFaaS gateway in order to perform the processing.</li> <li>Asynchronous through the path <code>/job/&lt;SERVICE_NAME&gt;</code>. This mode is used     to perform file-processing when files are uploaded to the input storage     provider, creating a Kubernetes job per service invocation.</li> </ul> <p>The content of the HTTP request body will be stored as a file that will be available via the <code>INPUT_FILE_PATH</code> environment variable to process it.</p> <p>A detailed specification of the OSCAR's API and its different paths can be found here.</p>"},{"location":"usage/#minio-storage-tab","title":"MinIO Storage Tab","text":"<p>MinIO Storage Tab is made to manage buckets without using MinIO UI. It simplifies the process. From MinIO Storage Tab, buckets can be created or removed and folders inside them. Furthermore, files can be uploaded to the buckets and downloaded from them. Each time a service is created or submitted an edit, the buckets that are not created will be formed.</p>"},{"location":"usage/#uploading-files","title":"Uploading files","text":"<p>Once a service has been created, it can be invoked by uploading files to its input bucket/folder. This can be done through the MinIO web interface (accessible from the Kubernetes frontend IP, on port <code>30300</code>) or from the \"Minio Storage\" section in the side menu of the OSCAR web interface. Expanding down that menu will list the buckets created and, by clicking on their name, you will be able to see their content, upload and download files.</p> <p></p> <p>To upload files, first click on the \"SELECT FILES\" button and choose the files you want to upload from your computer.</p> <p></p> <p>Once you have chosen the files to upload, simply click on the \"UPLOAD\" button and the file will be uploaded, raising an event that will trigger the service.</p> <p></p> <p>Note that the web interface includes a preview button for some file formats, such as images.</p> <p></p>"},{"location":"usage/#service-status-and-logs","title":"Service status and logs","text":"<p>When files are being processed by a service, it is important to know their status, as well as to observe the execution logs for testing. For this purpose, OSCAR includes a log view, accessible by clicking on the \"LOGS\" button in a service from the main view.</p> <p></p> <p>In this view you can see all the jobs created for a service, as well as their status (\"Pending\", \"Running\", \"Succeeded\" or \"Failed\") and their creation, start and finish time.</p> <p></p> <p>To view the logs generated by a job, simply click on the drop-down button located on the right.</p> <p></p> <p>The view also features options to refresh the status of one or all jobs, as well as to delete them.</p>"},{"location":"usage/#downloading-files-from-minio","title":"Downloading files from MinIO","text":"<p>Downloading files from the platform's MinIO storage provider can also be done using the OSCAR web interface. To do it, simply select one or more files and click on the button \"DOWNLOAD OBJECT\" (or \"DOWNLOAD ALL AS A ZIP\" if several files have been selected).</p> <p></p> <p>In the following picture you can see the preview of the resulting file after the execution triggered in the previous step.</p> <p></p>"},{"location":"usage/#deleting-services","title":"Deleting services","text":"<p>Services can be deleted by clicking on the trash can icon from the main view.</p> <p></p> <p>Once you have accepted the message shown in the image above, the service will be deleted after a few seconds.</p> <p></p>"}]}